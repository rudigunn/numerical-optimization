{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cad6e23-1a37-4799-b052-ec16b6e0872b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c4230c-87a2-4782-a2e5-95fc4b9c5279",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rosenbrock_f(x: np.array):\n",
    "    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ff75fe-90cd-4a6b-801d-5ef2aee6baab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grad_rosenbrock_f(x: np.array):\n",
    "    return np.array([-400 * (x[1] - x[0]**2) * x[0] - 2 * (1 - x[0]), 200 * (x[1] - x[0]**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9083b3e0-e119-4ef2-845c-3d4be56ecdff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x: np.array):\n",
    "    return 150 * (x[0] * x[1])**2 + (0.5 * x[0] + 2 * x[1] - 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff12dc4c-7cfc-486b-b263-0fe9a6a3b686",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grad_f(x: np.array):\n",
    "    return np.array([300 * x[0] * x[1]**2 + (0.5 * x[0] + 2 * x[1] - 2), 300 * x[0]**2 * x[1] + (0.5 * x[0] + 2 * x[1] - 2) * 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299e72be-d9fd-42eb-9e7e-e9d52ffec663",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def backtracking_line_search(func, xk, pk, grad_fk, alpha=1, rho=0.3, c=5e-4):\n",
    "    while func(xk + alpha * pk) > func(xk) + c * alpha * np.dot(grad_fk.T, pk):\n",
    "        alpha *= rho\n",
    "\n",
    "    if alpha < 1e-9:\n",
    "        alpha = 1\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3d6be7-fb87-4426-a198-de3daa13ba7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "solution_rosenbrock = np.array([1.0, 1.0])\n",
    "solutions_second_function = np.array([[4.0, 0.0], [0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad87f1-cf86-433f-bb27-e53da582e715",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Runs with exact derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ca9824-c8cb-4265-99cd-69a89297fd7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [1.2 1.2]:\n",
      "{'distance_to_solution': 2.651650731357318e-12,\n",
      " 'iteration': 13,\n",
      " 'x_k+1': array([1., 1.]),\n",
      " '|grad_f_k+1|': 3.5158764953239405e-11}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [-1.2  1. ]:\n",
      "{'distance_to_solution': 5.121067746494062e-09,\n",
      " 'iteration': 54,\n",
      " 'x_k+1': array([1., 1.]),\n",
      " '|grad_f_k+1|': 1.1067690541327862e-07}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [0.2 0.8]:\n",
      "{'distance_to_solution': 7.181383329974395e-09,\n",
      " 'iteration': 22,\n",
      " 'x_k+1': array([1.        , 0.99999999]),\n",
      " '|grad_f_k+1|': 1.6003320480869805e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 with Rosenbrock function\n",
    "starting_points = [np.array([1.2, 1.2]), np.array([-1.2, 1.0]), np.array([0.2, 0.8])]\n",
    "\n",
    "def sr1_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = grad_rosenbrock_f(xk)\n",
    "        pk = -np.linalg.solve(Bk, grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(rosenbrock_f, xk, pk, grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        grad_fk1 = grad_rosenbrock_f(xk1)\n",
    "        yk = grad_fk1 - grad_fk\n",
    "        \n",
    "        ys = yk - Bk @ sk\n",
    "        ys_T_s = ys.T @ sk\n",
    "        Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "\n",
    "        sy = sk - Hk @ yk\n",
    "        sy_T_y = sy.T @ yk\n",
    "        Hk1 = Hk + np.outer(sy, sy) / sy_T_y\n",
    "\n",
    "        dist_to_solution = np.linalg.norm(xk1 - solution_rosenbrock)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_solution\": dist_to_solution,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "221029ef-26cb-4ee7-a837-74143007e686",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [-0.2  1.2]:\n",
      "{'distance_to_nearest_solution': 9.112444517832828e-09,\n",
      " 'iteration': 7,\n",
      " 'x_k+1': array([9.22990593e-11, 9.99999991e-01]),\n",
      " '|grad_f_k+1|': 7.333074226228451e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [3.8 0.1]:\n",
      "{'distance_to_nearest_solution': 3.2561597881480904e-10,\n",
      " 'iteration': 7,\n",
      " 'x_k+1': array([4.00000000e+00, 1.11272826e-14]),\n",
      " '|grad_f_k+1|': 6.195021989785833e-10}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [1.9 0.6]:\n",
      "{'distance_to_nearest_solution': 8.074156338677283e-10,\n",
      " 'iteration': 13,\n",
      " 'x_k+1': array([ 4.00000000e+00, -1.38724384e-11]),\n",
      " '|grad_f_k+1|': 6.831463899070577e-08}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 with second function\n",
    "starting_points = [np.array([-0.2, 1.2]), np.array([3.8, 0.1]), np.array([1.9, 0.6])]\n",
    "\n",
    "def sr1_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = grad_f(xk)\n",
    "        pk = -np.linalg.solve(Bk, grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(f, xk, pk, grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        grad_fk1 = grad_f(xk1)\n",
    "        yk = grad_fk1 - grad_fk\n",
    "        \n",
    "        ys = yk - Bk @ sk\n",
    "        ys_T_s = ys.T @ sk\n",
    "        Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "\n",
    "        sy = sk - Hk @ yk\n",
    "        sy_T_y = sy.T @ yk\n",
    "        Hk1 = Hk + np.outer(sy, sy) / sy_T_y\n",
    "\n",
    "        distances_to_solutions = np.linalg.norm(xk1 - solutions_second_function, axis=1)\n",
    "        distance_to_nearest_solution = np.min(distances_to_solutions)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_nearest_solution\": distance_to_nearest_solution,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d2ac5fd-01a5-4dbb-a49e-fe1fef74ff8c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [1.2 1.2]:\n",
      "{'distance_to_solution': 2.5455463464545344e-08,\n",
      " 'iteration': 11,\n",
      " 'x_k+1': array([1.00000001, 1.00000002]),\n",
      " '|grad_f_k+1|': 8.059309414894322e-07}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [-1.2  1. ]:\n",
      "{'distance_to_solution': 7.81050225096746e-10,\n",
      " 'iteration': 34,\n",
      " 'x_k+1': array([1., 1.]),\n",
      " '|grad_f_k+1|': 2.026865758859956e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [0.2 0.8]:\n",
      "{'distance_to_solution': 1.3388087311238321e-08,\n",
      " 'iteration': 22,\n",
      " 'x_k+1': array([1.00000001, 1.00000001]),\n",
      " '|grad_f_k+1|': 1.6274479471455825e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton BFGS method with Rosenbrock function\n",
    "starting_points = [np.array([1.2, 1.2]), np.array([-1.2, 1.0]), np.array([0.2, 0.8])]\n",
    "\n",
    "def bfgs_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = grad_rosenbrock_f(xk)\n",
    "        pk = -np.linalg.solve(Bk, grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(rosenbrock_f, xk, pk, grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        grad_fk1 = grad_rosenbrock_f(xk1)\n",
    "        yk = grad_fk1 - grad_fk\n",
    "        \n",
    "        rho_k = 1 / (yk.T @ sk)\n",
    "        Bk1 = Bk - (Bk @ np.outer(sk, sk) @ Bk) / (sk.T @ Bk @ sk) + np.outer(yk, yk) / (yk.T @ sk) \n",
    "        Hk1 = (np.eye(2) - rho_k * sk @ yk.T) @ Hk @ (np.eye(2) - rho_k * yk @ sk.T) + rho_k * sk @ sk.T\n",
    "\n",
    "        dist_to_solution = np.linalg.norm(xk1 - solution_rosenbrock)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_solution\": dist_to_solution,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = bfgs_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4366c0a7-b1a7-43be-994d-94e628b65254",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [-0.2  1.2]:\n",
      "{'distance_to_nearest_solution': 8.899903636802087e-09,\n",
      " 'iteration': 8,\n",
      " 'x_k+1': array([1.67086050e-10, 9.99999991e-01]),\n",
      " '|grad_f_k+1|': 7.79144419305197e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [3.8 0.1]:\n",
      "{'distance_to_nearest_solution': 1.3522392827270172e-09,\n",
      " 'iteration': 11,\n",
      " 'x_k+1': array([4.00000000e+00, 1.65898616e-11]),\n",
      " '|grad_f_k+1|': 7.70624610741654e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [1.9 0.6]:\n",
      "{'distance_to_nearest_solution': 1.3207441002686676e-09,\n",
      " 'iteration': 17,\n",
      " 'x_k+1': array([4.00000000e+00, 7.30722494e-11]),\n",
      " '|grad_f_k+1|': 3.4869431022878624e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton BFGS method with second function\n",
    "starting_points = [np.array([-0.2, 1.2]), np.array([3.8, 0.1]), np.array([1.9, 0.6])]\n",
    "\n",
    "def bfgs_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = grad_f(xk)\n",
    "        pk = -np.linalg.solve(Bk, grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(f, xk, pk, grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        grad_fk1 = grad_f(xk1)\n",
    "        yk = grad_fk1 - grad_fk\n",
    "        \n",
    "        rho_k = 1 / (yk.T @ sk)\n",
    "        Bk1 = Bk - (Bk @ np.outer(sk, sk) @ Bk) / (sk.T @ Bk @ sk) + np.outer(yk, yk) / (yk.T @ sk) \n",
    "        Hk1 = (np.eye(2) - rho_k * sk @ yk.T) @ Hk @ (np.eye(2) - rho_k * yk @ sk.T) + rho_k * sk @ sk.T\n",
    "        \n",
    "        distances_to_solutions = np.linalg.norm(xk1 - solutions_second_function, axis=1)\n",
    "        distance_to_nearest_solution = np.min(distances_to_solutions)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_nearest_solution\": distance_to_nearest_solution,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = bfgs_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b1c7bc7-f2c0-4f19-b554-6c23794cf029",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [1.2 1.2]:\n",
      "{'delta': 5.960464477539063e-08,\n",
      " 'distance_to_solution': 3.101184469905063e-09,\n",
      " 'iteration': 71,\n",
      " 'x_k+1': array([1., 1.]),\n",
      " '|grad_f_k+1|': 7.524967540362846e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [-1.2  1. ]:\n",
      "{'delta': 0.03125,\n",
      " 'distance_to_solution': 3.127213837398988e-08,\n",
      " 'iteration': 294,\n",
      " 'x_k+1': array([0.99999999, 0.99999997]),\n",
      " '|grad_f_k+1|': 8.103543645537549e-07}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: [0.2 0.8]:\n",
      "{'delta': 0.015625,\n",
      " 'distance_to_solution': 7.98767900534559e-07,\n",
      " 'iteration': 297,\n",
      " 'x_k+1': array([0.99999964, 0.99999928]),\n",
      " '|grad_f_k+1|': 8.829204263958739e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 (trust region) with Rosenbrock function\n",
    "starting_points = [np.array([1.2, 1.2]), np.array([-1.2, 1.0]), np.array([0.2, 0.8])]\n",
    "\n",
    "def sr1_trust_region_method(x0, B0, max_iter=10000, tol=1e-6, trust_region_delta=1.0, eta=1e-4, r=0.5):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = grad_rosenbrock_f(xk)\n",
    "        if np.linalg.norm(grad_fk) < tol:\n",
    "            break\n",
    "            \n",
    "        sk = -np.linalg.solve(Bk, grad_fk)\n",
    "        if np.linalg.norm(sk) > trust_region_delta:\n",
    "            sk = sk * (trust_region_delta / np.linalg.norm(sk)) \n",
    "\n",
    "        grad_fk1 = grad_rosenbrock_f(xk + sk)\n",
    "        yk = grad_fk1 - grad_fk\n",
    "\n",
    "        fk = rosenbrock_f(xk)\n",
    "        fk1 = rosenbrock_f(xk + sk)\n",
    "        ared = fk - fk1\n",
    "        pred = -grad_fk.T @ sk - 0.5 * sk.T @ Bk @ sk\n",
    "\n",
    "        if ared / pred > eta:\n",
    "            xk1 = xk + sk\n",
    "        else:\n",
    "            xk1 = xk\n",
    "\n",
    "        if ared / pred > 0.75:\n",
    "            if np.linalg.norm(sk) <= 0.8 * trust_region_delta:\n",
    "                trust_region_delta = trust_region_delta\n",
    "            else:\n",
    "                trust_region_delta = 2 * trust_region_delta\n",
    "        elif ared / pred >= 0.1 and ared / pred <= 0.75:\n",
    "            trust_region_delta = trust_region_delta\n",
    "        else:\n",
    "            trust_region_delta = 0.5 * trust_region_delta\n",
    "        \n",
    "        # check 6.26\n",
    "        if np.linalg.norm(sk.T @ (yk - Bk @ sk)) >= r * np.linalg.norm(sk) * np.linalg.norm(yk - Bk @ sk):\n",
    "            ys = yk - Bk @ sk\n",
    "            ys_T_s = ys.T @ sk\n",
    "            Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "        else:\n",
    "            Bk1 = Bk\n",
    "\n",
    "        dist_to_solution = np.linalg.norm(xk1 - solution_rosenbrock)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_solution\": dist_to_solution,\n",
    "            \"delta\": trust_region_delta,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1)\n",
    "        })\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_trust_region_method(starting_point, np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (exact derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027bce27-6c75-47fe-a694-16c04ac1dcd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [-0.2  1.2]:\n",
      "{'delta': 0.25,\n",
      " 'distance_to_nearest_solution': 8.234394820251813e-11,\n",
      " 'iteration': 11,\n",
      " 'x_k+1': array([3.31869207e-11, 1.00000000e+00]),\n",
      " '|grad_f_k+1|': 9.836591285286996e-09}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [3.8 0.1]:\n",
      "{'delta': 1.0,\n",
      " 'distance_to_nearest_solution': 1.1591792835831045e-09,\n",
      " 'iteration': 23,\n",
      " 'x_k+1': array([4.00000000e+00, 2.05241968e-10]),\n",
      " '|grad_f_k+1|': 9.845216668908105e-07}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: [1.9 0.6]:\n",
      "{'delta': 0.5,\n",
      " 'distance_to_nearest_solution': 1.4916419308029137e-08,\n",
      " 'iteration': 17,\n",
      " 'x_k+1': array([-1.22415927e-09,  9.99999985e-01]),\n",
      " '|grad_f_k+1|': 4.157064483732382e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 (trust region) with second function\n",
    "starting_points = [np.array([-0.2, 1.2]), np.array([3.8, 0.1]), np.array([1.9, 0.6])]\n",
    "\n",
    "def sr1_trust_region_method(x0, B0, max_iter=10000, tol=1e-6, trust_region_delta=1.0, eta=1e-4, r=0.2):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = grad_f(xk)\n",
    "        if np.linalg.norm(grad_fk) < tol:\n",
    "            break\n",
    "            \n",
    "        sk = -np.linalg.solve(Bk, grad_fk)\n",
    "        if np.linalg.norm(sk) > trust_region_delta:\n",
    "            sk = sk * (trust_region_delta / np.linalg.norm(sk)) \n",
    "\n",
    "        grad_fk1 = grad_f(xk + sk)\n",
    "        yk = grad_fk1 - grad_fk\n",
    "\n",
    "        fk = f(xk)\n",
    "        fk1 = f(xk + sk)\n",
    "        ared = fk - fk1\n",
    "        pred = -grad_fk.T @ sk - 0.5 * sk.T @ Bk @ sk\n",
    "\n",
    "        if ared / pred > eta:\n",
    "            xk1 = xk + sk\n",
    "        else:\n",
    "            xk1 = xk\n",
    "\n",
    "        if ared / pred > 0.75:\n",
    "            if np.linalg.norm(sk) <= 0.8 * trust_region_delta:\n",
    "                trust_region_delta = trust_region_delta\n",
    "            else:\n",
    "                trust_region_delta = 2 * trust_region_delta\n",
    "        elif ared / pred >= 0.1 and ared / pred <= 0.75:\n",
    "            trust_region_delta = trust_region_delta\n",
    "        else:\n",
    "            trust_region_delta = 0.5 * trust_region_delta\n",
    "        \n",
    "        # check 6.26\n",
    "        if abs(sk.T @ (yk - Bk @ sk)) >= r * np.linalg.norm(sk) * np.linalg.norm(yk - Bk @ sk):\n",
    "            ys = yk - Bk @ sk\n",
    "            ys_T_s = ys.T @ sk\n",
    "            Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "        else:\n",
    "            Bk1 = Bk\n",
    "\n",
    "        distances_to_solutions = np.linalg.norm(xk1 - solutions_second_function, axis=1)\n",
    "        distance_to_nearest_solution = np.min(distances_to_solutions)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_nearest_solution\": distance_to_nearest_solution,\n",
    "            \"delta\": trust_region_delta,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1)\n",
    "        })\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_trust_region_method(starting_point, np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (exact derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3a48a-17a6-4432-b52f-487862b74ee6",
   "metadata": {},
   "source": [
    "## Runs with approximated derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1aa088-291c-4a2b-8f82-1156a8f0c133",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually calculated unit roundoff value (u): 1.1102230246251565e-16\n",
      "Epsilon from manually calculated u: 1.0536712127723509e-08\n"
     ]
    }
   ],
   "source": [
    "u = 1.0\n",
    "while 1.0 + u != 1.0:\n",
    "    u /= 2\n",
    "epsilon = np.sqrt(u)\n",
    "    \n",
    "# Print the unit roundoff value\n",
    "print(\"Manually calculated unit roundoff value (u):\", u)\n",
    "print(\"Epsilon from manually calculated u:\", epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a137e610-5b1d-4d70-81ce-302bfad2dfbc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon for central-difference Method: 4.806217383937355e-06\n"
     ]
    }
   ],
   "source": [
    "central_epsilon = u**(1/3)\n",
    "print(f\"Epsilon for central-difference Method: {central_epsilon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d7b06b0-4cd9-4e5d-9d77-8a05e07aa1e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_difference(func: callable, x: np.ndarray, epsilon: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    func: Function you want to approximate the derivative of\n",
    "    x: Point where at which you want the approximation of the derivative\n",
    "    epsilon: very small number typically sqrt(u), where u is unit-roundoff\n",
    "    Returns:\n",
    "    Approximation of derivative at point x\n",
    "    \"\"\"\n",
    "    dim = x.shape[0] if x.shape != () else 1\n",
    "    grad = np.zeros(dim)\n",
    "    \n",
    "    for i in range(dim):\n",
    "        e = np.zeros(dim)\n",
    "        e[i] = 1\n",
    "        grad_i = (func(x + epsilon * e) - func(x)) / epsilon\n",
    "        grad[i] = grad_i\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75c3dd1-e9eb-4041-ae02-3fb4289a7818",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def central_difference(func: callable, x: np.ndarray, epsilon: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    func: Function you want to approximate the derivative of\n",
    "    x: Point where at which you want the approximation of the derivative\n",
    "    epsilon: very small number typically sqrt(u), where u is unit-roundoff\n",
    "    Returns:\n",
    "    Approximation of derivative at point x\n",
    "    \"\"\"\n",
    "    dim = x.shape[0] if x.shape != () else 1\n",
    "    grad = np.zeros(dim)\n",
    "    \n",
    "    for i in range(dim):\n",
    "        e = np.zeros(dim)\n",
    "        e[i] = 1\n",
    "        grad_i = (func(x + epsilon * e) - func(x - epsilon * e)) / (2 * epsilon)\n",
    "        grad[i] = grad_i\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f540ed5-5009-4e07-8caf-d2c7718d1903",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [1.2 1.2]:\n",
      "{'distance_to_solution': 7.084685644326211e-06,\n",
      " 'iteration': 13,\n",
      " 'x_k+1': array([0.99999683, 0.99999366]),\n",
      " '|approx_grad_f_k+1|': 3.827147777230628e-11}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [-1.2  1. ]:\n",
      "{'distance_to_solution': 7.084691381291606e-06,\n",
      " 'iteration': 51,\n",
      " 'x_k+1': array([0.99999683, 0.99999366]),\n",
      " '|approx_grad_f_k+1|': 1.6154802336819816e-09}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [0.2 0.8]:\n",
      "{'distance_to_solution': 7.093491306622038e-06,\n",
      " 'iteration': 22,\n",
      " 'x_k+1': array([0.99999683, 0.99999365]),\n",
      " '|approx_grad_f_k+1|': 1.7123022855395305e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 with Rosenbrock function (approximated gradients)\n",
    "starting_points = [np.array([1.2, 1.2]), np.array([-1.2, 1.0]), np.array([0.2, 0.8])]\n",
    "\n",
    "def sr1_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        approx_grad_fk = forward_difference(rosenbrock_f, xk, epsilon)\n",
    "        pk = -np.linalg.solve(Bk, approx_grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(rosenbrock_f, xk, pk, approx_grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        approx_grad_fk1 = forward_difference(rosenbrock_f, xk1, epsilon)\n",
    "        yk = approx_grad_fk1 - approx_grad_fk\n",
    "        \n",
    "        ys = yk - Bk @ sk\n",
    "        ys_T_s = ys.T @ sk\n",
    "        Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "\n",
    "        sy = sk - Hk @ yk\n",
    "        sy_T_y = sy.T @ yk\n",
    "        Hk1 = Hk + np.outer(sy, sy) / sy_T_y\n",
    "\n",
    "        dist_to_solution = np.linalg.norm(xk1 - solution_rosenbrock)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_solution\": dist_to_solution,\n",
    "            \"|approx_grad_f_k+1|\": np.linalg.norm(approx_grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(approx_grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48428dd1-b486-4396-8e25-365240f52008",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [-0.2  1.2]:\n",
      "{'distance_to_nearest_solution': 1.4047286282667243e-08,\n",
      " 'iteration': 7,\n",
      " 'x_k+1': array([-5.14973344e-09,  9.99999987e-01]),\n",
      " '|approx_grad_f_k+1|': 7.332596651988921e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [3.8 0.1]:\n",
      "{'distance_to_nearest_solution': 1.6378424629019884e-08,\n",
      " 'iteration': 7,\n",
      " 'x_k+1': array([ 4.00000002e+00, -5.27492953e-09]),\n",
      " '|approx_grad_f_k+1|': 6.156688753962577e-10}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [1.9 0.6]:\n",
      "{'distance_to_nearest_solution': 1.592713721606492e-08,\n",
      " 'iteration': 13,\n",
      " 'x_k+1': array([ 4.00000002e+00, -5.28881811e-09]),\n",
      " '|approx_grad_f_k+1|': 6.833609083343114e-08}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 with second function (approximated gradients)\n",
    "starting_points = [np.array([-0.2, 1.2]), np.array([3.8, 0.1]), np.array([1.9, 0.6])]\n",
    "\n",
    "def sr1_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        approx_grad_fk = forward_difference(f, xk, epsilon)\n",
    "        pk = -np.linalg.solve(Bk, approx_grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(f, xk, pk, approx_grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        approx_grad_fk1 = forward_difference(f, xk1, epsilon)\n",
    "        yk = approx_grad_fk1 - approx_grad_fk\n",
    "        \n",
    "        ys = yk - Bk @ sk\n",
    "        ys_T_s = ys.T @ sk\n",
    "        Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "\n",
    "        sy = sk - Hk @ yk\n",
    "        sy_T_y = sy.T @ yk\n",
    "        Hk1 = Hk + np.outer(sy, sy) / sy_T_y\n",
    "\n",
    "        distances_to_solutions = np.linalg.norm(xk1 - solutions_second_function, axis=1)\n",
    "        distance_to_nearest_solution = np.min(distances_to_solutions)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_nearest_solution\": distance_to_nearest_solution,\n",
    "            \"|approx_grad_f_k+1|\": np.linalg.norm(approx_grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(approx_grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c816b44b-935a-4b68-9e77-1830f6f10607",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [1.2 1.2]:\n",
      "{'distance_to_solution': 7.059203135883713e-06,\n",
      " 'iteration': 11,\n",
      " 'x_k+1': array([0.99999684, 0.99999369]),\n",
      " '|approx_grad_f_k+1|': 8.071409078255463e-07}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [-1.2  1. ]:\n",
      "{'distance_to_solution': 7.081566144358239e-06,\n",
      " 'iteration': 34,\n",
      " 'x_k+1': array([0.99999683, 0.99999367]),\n",
      " '|approx_grad_f_k+1|': 1.46411286399573e-07}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [0.2 0.8]:\n",
      "{'distance_to_solution': 7.07130330127744e-06,\n",
      " 'iteration': 22,\n",
      " 'x_k+1': array([0.99999684, 0.99999367]),\n",
      " '|approx_grad_f_k+1|': 1.6276285020566664e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton BFGS method with Rosenbrock function (approximated gradients)\n",
    "starting_points = [np.array([1.2, 1.2]), np.array([-1.2, 1.0]), np.array([0.2, 0.8])]\n",
    "\n",
    "def bfgs_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        approx_grad_fk = forward_difference(rosenbrock_f, xk, epsilon)\n",
    "        pk = -np.linalg.solve(Bk, approx_grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(rosenbrock_f, xk, pk, approx_grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        approx_grad_fk1 = forward_difference(rosenbrock_f, xk1, epsilon)\n",
    "        yk = approx_grad_fk1 - approx_grad_fk\n",
    "        \n",
    "        rho_k = 1 / (yk.T @ sk)\n",
    "        Bk1 = Bk - (Bk @ np.outer(sk, sk) @ Bk) / (sk.T @ Bk @ sk) + np.outer(yk, yk) / (yk.T @ sk) \n",
    "        Hk1 = (np.eye(2) - rho_k * sk @ yk.T) @ Hk @ (np.eye(2) - rho_k * yk @ sk.T) + rho_k * sk @ sk.T\n",
    "\n",
    "        dist_to_solution = np.linalg.norm(xk1 - solution_rosenbrock)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_solution\": dist_to_solution,\n",
    "            \"|approx_grad_f_k+1|\": np.linalg.norm(approx_grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(approx_grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = bfgs_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"BFGS method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28501534-3b42-4d50-8bc0-3a23fdaa590a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [-0.2  1.2]:\n",
      "{'distance_to_nearest_solution': 1.3821570298912018e-08,\n",
      " 'iteration': 8,\n",
      " 'x_k+1': array([-5.07492386e-09,  9.99999987e-01]),\n",
      " '|approx_grad_f_k+1|': 7.791482203545763e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [3.8 0.1]:\n",
      "{'distance_to_nearest_solution': 1.5404521134960973e-08,\n",
      " 'iteration': 11,\n",
      " 'x_k+1': array([ 4.00000001e+00, -5.25835167e-09]),\n",
      " '|approx_grad_f_k+1|': 7.706232900378349e-08}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [1.9 0.6]:\n",
      "{'distance_to_nearest_solution': 1.541675855282461e-08,\n",
      " 'iteration': 17,\n",
      " 'x_k+1': array([ 4.00000001e+00, -5.20187152e-09]),\n",
      " '|approx_grad_f_k+1|': 3.4868335547299253e-07}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton BFGS method with second function (approximated gradients)\n",
    "starting_points = [np.array([-0.2, 1.2]), np.array([3.8, 0.1]), np.array([1.9, 0.6])]\n",
    "\n",
    "def bfgs_method(x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    Hk = H0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        approx_grad_fk = forward_difference(f, xk, epsilon)\n",
    "        pk = -np.linalg.solve(Bk, approx_grad_fk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(f, xk, pk, approx_grad_fk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        approx_grad_fk1 = forward_difference(f, xk1, epsilon)\n",
    "        yk = approx_grad_fk1 - approx_grad_fk\n",
    "        \n",
    "        rho_k = 1 / (yk.T @ sk)\n",
    "        Bk1 = Bk - (Bk @ np.outer(sk, sk) @ Bk) / (sk.T @ Bk @ sk) + np.outer(yk, yk) / (yk.T @ sk) \n",
    "        Hk1 = (np.eye(2) - rho_k * sk @ yk.T) @ Hk @ (np.eye(2) - rho_k * yk @ sk.T) + rho_k * sk @ sk.T\n",
    "\n",
    "        distances_to_solutions = np.linalg.norm(xk1 - solutions_second_function, axis=1)\n",
    "        distance_to_nearest_solution = np.min(distances_to_solutions)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_nearest_solution\": distance_to_nearest_solution,\n",
    "            \"|approx_grad_f_k+1|\": np.linalg.norm(approx_grad_fk1)\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(approx_grad_fk1) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = bfgs_method(starting_point, np.eye(2), np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"BFGS method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1db5b588-6430-4501-abdf-0091b25e7666",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [1.2 1.2]:\n",
      "{'delta': 0.03125,\n",
      " 'distance_to_solution': 2.5802685631495484e-06,\n",
      " 'iteration': 252,\n",
      " 'x_k+1': array([0.99999881, 0.99999771]),\n",
      " '|approx_grad_f_k+1|': 3.6790712570867334e-05}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [-1.2  1. ]:\n",
      "{'delta': 0.015625,\n",
      " 'distance_to_solution': 7.502412132112569e-05,\n",
      " 'iteration': 279,\n",
      " 'x_k+1': array([0.99996654, 0.99993285]),\n",
      " '|approx_grad_f_k+1|': 4.946973149100229e-05}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: [0.2 0.8]:\n",
      "{'delta': 0.00390625,\n",
      " 'distance_to_solution': 0.00010201688853284582,\n",
      " 'iteration': 603,\n",
      " 'x_k+1': array([0.99995452, 0.99990868]),\n",
      " '|approx_grad_f_k+1|': 9.439209076347814e-05}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 (trust region) with Rosenbrock function (approximated gradients)\n",
    "starting_points = [np.array([1.2, 1.2]), np.array([-1.2, 1.0]), np.array([0.2, 0.8])]\n",
    "\n",
    "def sr1_trust_region_method(x0, B0, max_iter=10000, tol=1e-4, trust_region_delta=1.0, eta=1e-4, r=0.6):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        approx_grad_fk = forward_difference(rosenbrock_f, xk, epsilon)\n",
    "        if np.linalg.norm(approx_grad_fk) < tol:\n",
    "            break\n",
    "            \n",
    "        sk = -np.linalg.solve(Bk, approx_grad_fk)\n",
    "        if np.linalg.norm(sk) > trust_region_delta:\n",
    "            sk = sk * (trust_region_delta / np.linalg.norm(sk)) \n",
    "\n",
    "        approx_grad_fk1 = forward_difference(rosenbrock_f, xk + sk, epsilon)\n",
    "        yk = approx_grad_fk1 - approx_grad_fk\n",
    "\n",
    "        fk = rosenbrock_f(xk)\n",
    "        fk1 = rosenbrock_f(xk + sk)\n",
    "        ared = fk - fk1\n",
    "        pred = -approx_grad_fk.T @ sk - 0.5 * sk.T @ Bk @ sk\n",
    "\n",
    "        if ared / pred > eta:\n",
    "            xk1 = xk + sk\n",
    "        else:\n",
    "            xk1 = xk\n",
    "\n",
    "        if ared / pred > 0.75:\n",
    "            if np.linalg.norm(sk) <= 0.8 * trust_region_delta:\n",
    "                trust_region_delta = trust_region_delta\n",
    "            else:\n",
    "                trust_region_delta = 2 * trust_region_delta\n",
    "        elif ared / pred >= 0.1 and ared / pred <= 0.75:\n",
    "            trust_region_delta = trust_region_delta\n",
    "        else:\n",
    "            trust_region_delta = 0.5 * trust_region_delta\n",
    "        \n",
    "        # check 6.26\n",
    "        if np.linalg.norm(sk.T @ (yk - Bk @ sk)) >= r * np.linalg.norm(sk) * np.linalg.norm(yk - Bk @ sk):\n",
    "            ys = yk - Bk @ sk\n",
    "            ys_T_s = ys.T @ sk\n",
    "            Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "        else:\n",
    "            Bk1 = Bk\n",
    "\n",
    "        dist_to_solution = np.linalg.norm(xk1 - solution_rosenbrock)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_solution\": dist_to_solution,\n",
    "            \"delta\": trust_region_delta,\n",
    "            \"|approx_grad_f_k+1|\": np.linalg.norm(approx_grad_fk1)\n",
    "        })\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_trust_region_method(starting_point, np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 (trust region) method with Rosenbrock function f(x) = 100(x2 − x1^2)^2 + (1 − x1)^2 (approximated derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47527ea7-1518-4fd5-a5f0-6b5542c54365",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 trust region method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [-0.2  1.2]:\n",
      "{'delta': 0.5,\n",
      " 'distance_to_nearest_solution': 1.75434290746335e-08,\n",
      " 'iteration': 10,\n",
      " 'x_k+1': array([5.63381230e-09, 1.00000002e+00]),\n",
      " '|approx_grad_f_k+1|': 3.3145714762079956e-06}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 trust region method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [3.8 0.1]:\n",
      "{'delta': 0.001953125,\n",
      " 'distance_to_nearest_solution': 5.598158626742398e-06,\n",
      " 'iteration': 5041,\n",
      " 'x_k+1': array([ 3.99999440e+00, -9.47821466e-10]),\n",
      " '|approx_grad_f_k+1|': 9.977221558170227e-06}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SR1 trust region method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: [1.9 0.6]:\n",
      "{'delta': 9.5367431640625e-07,\n",
      " 'distance_to_nearest_solution': 1.668724930623611e-08,\n",
      " 'iteration': 58,\n",
      " 'x_k+1': array([ 4.00000002e+00, -5.27494448e-09]),\n",
      " '|approx_grad_f_k+1|': 1.3902015095037274e-11}\n"
     ]
    }
   ],
   "source": [
    "# Quasi-Newton SR1 (trust region) with second function\n",
    "starting_points = [np.array([-0.2, 1.2]), np.array([3.8, 0.1]), np.array([1.9, 0.6])]\n",
    "\n",
    "def sr1_trust_region_method(x0, B0, max_iter=10000, tol=1e-5, trust_region_delta=1.0, eta=1e-4, r=0.3):\n",
    "    xk = x0\n",
    "    Bk = B0\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        approx_grad_fk = forward_difference(f, xk, epsilon)\n",
    "        if np.linalg.norm(approx_grad_fk) < tol:\n",
    "            break\n",
    "            \n",
    "        sk = -np.linalg.solve(Bk, approx_grad_fk)\n",
    "        if np.linalg.norm(sk) > trust_region_delta:\n",
    "            sk = sk * (trust_region_delta / np.linalg.norm(sk)) \n",
    "\n",
    "        approx_grad_fk1 = forward_difference(f, xk + sk, epsilon)\n",
    "        yk = approx_grad_fk1 - approx_grad_fk\n",
    "\n",
    "        fk = f(xk)\n",
    "        fk1 = f(xk + sk)\n",
    "        ared = fk - fk1\n",
    "        pred = -approx_grad_fk.T @ sk - 0.5 * sk.T @ Bk @ sk\n",
    "\n",
    "        if ared / pred > eta:\n",
    "            xk1 = xk + sk\n",
    "        else:\n",
    "            xk1 = xk\n",
    "\n",
    "        if ared / pred > 0.75:\n",
    "            if np.linalg.norm(sk) <= 0.8 * trust_region_delta:\n",
    "                trust_region_delta = trust_region_delta\n",
    "            else:\n",
    "                trust_region_delta = 2 * trust_region_delta\n",
    "        elif ared / pred >= 0.1 and ared / pred <= 0.75:\n",
    "            trust_region_delta = trust_region_delta\n",
    "        else:\n",
    "            trust_region_delta = 0.5 * trust_region_delta\n",
    "        \n",
    "        # check 6.26\n",
    "        if np.linalg.norm(sk.T @ (yk - Bk @ sk)) >= r * np.linalg.norm(sk) * np.linalg.norm(yk - Bk @ sk):\n",
    "            ys = yk - Bk @ sk\n",
    "            ys_T_s = ys.T @ sk\n",
    "            Bk1 = Bk + np.outer(ys, ys) / ys_T_s\n",
    "        else:\n",
    "            Bk1 = Bk\n",
    "\n",
    "        distances_to_solutions = np.linalg.norm(xk1 - solutions_second_function, axis=1)\n",
    "        distance_to_nearest_solution = np.min(distances_to_solutions)\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"distance_to_nearest_solution\": distance_to_nearest_solution,\n",
    "            \"delta\": trust_region_delta,\n",
    "            \"|approx_grad_f_k+1|\": np.linalg.norm(approx_grad_fk1)\n",
    "        })\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n",
    "\n",
    "for starting_point in starting_points:\n",
    "    sr1_results = sr1_trust_region_method(starting_point, np.eye(2))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"SR1 trust region method with f(x) = 150(x1x2)^2 + (0.5x1 + 2x2 − 2)^2 (approximated derivatives) and starting point: {starting_point}:\")\n",
    "    pprint(sr1_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dbd05-732c-4b7c-bd4f-584907163d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
