{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cad6e23-1a37-4799-b052-ec16b6e0872b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from torch.autograd.functional import jacobian, hessian\n",
    "import torch, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9059c",
   "metadata": {},
   "source": [
    "### Vanilla Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b039af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver():\n",
    "\n",
    "    def __init__(self, f, max_iter = 10_000, ro = 0.5, alpha_ini = 0.99, c = 0.45, alpha_f = None, iternad_processor = None) -> None:\n",
    "        self.f = f\n",
    "        self.ro = ro\n",
    "        self.alpha_ini = alpha_ini\n",
    "        self.c = c\n",
    "        self.iterands = 0\n",
    "        self.max_iter = max_iter\n",
    "        self.done = False\n",
    "\n",
    "    def solve(self, x):\n",
    "        x = self.tensorize(x)\n",
    "        self.iterands = 0\n",
    "        while not self.done and self.iterands < self.max_iter:\n",
    "            #print(f\".x_{len(self.iterands)} = {x}\")\n",
    "            self.iterands += 1\n",
    "            p = torch.reshape(self.get_p(x), x.shape)\n",
    "            x = x + self.get_alpha(p, x) * p\n",
    "        \"\"\"if self.stop_crit(x, verbose = True):\n",
    "            print(f\"Converged to the solution {x} after {self.iterands} steps\")\n",
    "        else:\n",
    "            print(f\"Failed to converge and ended in {x}\")\"\"\"\n",
    "        return x\n",
    "\n",
    "    def get_p(self, x):\n",
    "        pass\n",
    "\n",
    "    def get_alpha(self, p, x):\n",
    "        # Do the line search\n",
    "        alpha = self.alpha_ini\n",
    "        while self.f(x + alpha * p) > self.f(x) + self.c * alpha * p.T @ jacobian(self.f,x):\n",
    "            alpha *= self.ro\n",
    "        return alpha\n",
    "\n",
    "    def tensorize(self, x):\n",
    "        if type(x) in [int, float]: return torch.DoubleTensor([x])\n",
    "        else: return torch.DoubleTensor(x)\n",
    "\n",
    "class Newton(Solver):\n",
    "\n",
    "    def get_p(self, x):\n",
    "        hes = hessian(self.f, x)\n",
    "        down_grad = -jacobian(self.f, x)\n",
    "        if np.linalg.norm(down_grad.detach().numpy()) < 1e-6:\n",
    "            self.done = True\n",
    "        p = np.linalg.solve(hes, down_grad)\n",
    "        return torch.DoubleTensor(p)\n",
    "    \n",
    "class GradStop():\n",
    "\n",
    "    def __init__(self, f = None, suf_grad = 1e-6) -> None:\n",
    "        self.f = f\n",
    "        self.suf_grad = suf_grad\n",
    "\n",
    "    def __call__(self, x, verbose = False):\n",
    "        grad_norm = np.linalg.norm(jacobian(self.f, x).detach().numpy())\n",
    "        solved = grad_norm < self.suf_grad\n",
    "        #if solved and verbose:\n",
    "        if verbose: print(f\"Gradient norm {grad_norm}.\")\n",
    "        return solved "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ef2fe",
   "metadata": {},
   "source": [
    "### Quasi-Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "299e72be-d9fd-42eb-9e7e-e9d52ffec663",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def backtracking_line_search(func, xk, pk, alpha=1, rho=0.5, c=1e-4):\n",
    "    grad_fk = jacobian(func,torch.DoubleTensor(xk))#.detach().numpy()\n",
    "    dot_prod = torch.dot(grad_fk, pk)\n",
    "    while func(xk + alpha * pk) > func(xk) + c * alpha * dot_prod:\n",
    "        alpha *= rho\n",
    "\n",
    "    if alpha < 1e-8:\n",
    "        alpha = 1\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01ca9824-c8cb-4265-99cd-69a89297fd7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Quasi-Newton SR1\n",
    "def sr1_method(f, x0, B0, H0, max_iter=10000, tol=1e-6):\n",
    "    xk = x0\n",
    "    Bk = torch.DoubleTensor(B0)\n",
    "    Hk = torch.DoubleTensor(H0)\n",
    "    results = []\n",
    "    for k in range(max_iter):\n",
    "        grad_fk = jacobian(f, torch.DoubleTensor(xk))#.detach().numpy()\n",
    "        pk = -np.linalg.solve(Bk, grad_fk.detach().numpy())\n",
    "        pk = torch.DoubleTensor(pk)\n",
    "\n",
    "        alpha_k = backtracking_line_search(f, xk, pk)\n",
    "\n",
    "        xk1 = xk + alpha_k * pk\n",
    "        sk = xk1 - xk\n",
    "        grad_fk1 = jacobian(f, torch.DoubleTensor(xk1))#.detach().numpy()\n",
    "        yk = grad_fk1 - grad_fk\n",
    "        \n",
    "        ys = yk - Bk @ sk\n",
    "        ys_T_s = ys.T @ sk\n",
    "        Bk1 = Bk + torch.outer(ys, ys) / ys_T_s\n",
    "\n",
    "        sy = sk - Hk @ yk\n",
    "        sy_T_y = sy.T @ yk\n",
    "        Hk1 = Hk + torch.outer(sy, sy) / sy_T_y\n",
    "        \n",
    "        results.append({\n",
    "            \"iteration\": k,\n",
    "            \"x_k+1\": xk1,\n",
    "            \"s_k\": sk,\n",
    "            \"y_k\": yk,\n",
    "            \"B_k+1\": Bk1,\n",
    "            \"H_k+1\": Hk1,\n",
    "            \"(sk - Hkyk)^Tyk\": sy_T_y,\n",
    "            \"|grad_f_k+1|\": np.linalg.norm(grad_fk1.detach().numpy())\n",
    "        })\n",
    "\n",
    "        if np.linalg.norm(grad_fk1.detach().numpy()) < tol:\n",
    "            break\n",
    "\n",
    "        xk, Bk = xk1, Bk1\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24692905",
   "metadata": {},
   "source": [
    "### Race setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d39d6403-3cec-431d-98c4-3b06daf5b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def race(f, starting_point, verbose = True):\n",
    "    starting_point = torch.DoubleTensor(starting_point)\n",
    "    # SR1\n",
    "    t1 = time.time()\n",
    "    sr1_method(f, starting_point, np.eye(len(starting_point)),  np.eye(len(starting_point)))\n",
    "    t2 = time.time()\n",
    "    sr_time = t2 - t1\n",
    "    if verbose: print(f\"SR1 needed {sr_time} seconds\")\n",
    "    # Newton\n",
    "    solver = Newton(f)\n",
    "    t1 = time.time()\n",
    "    solver.solve(starting_point)\n",
    "    t2 = time.time()\n",
    "    nw_time = t2 - t1\n",
    "    if verbose: print(f\"Newton needed {nw_time} seconds\")\n",
    "    return sr_time, nw_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11654875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_race(f, starting_point, n = 20):\n",
    "    srs = 0\n",
    "    nws = 0\n",
    "    for i in range(n):\n",
    "        srs_res, nws_res = race(f, starting_point, verbose=False)\n",
    "        srs += srs_res\n",
    "        nws += nws_res\n",
    "    print(f\"SR1 needed {srs/n} seconds\")\n",
    "    print(f\"Newton needed {nws/n} seconds\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd00959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock_f(x):\n",
    "    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e13122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR1 needed 0.03046987533569336 seconds\n",
      "Newton needed 0.0198876428604126 seconds\n"
     ]
    }
   ],
   "source": [
    "robust_race(rosenbrock_f, [1.2,1.0], n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0545e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_polynomial_f(x):\n",
    "    if not np.random.randint(0, 5): return x[0]**2 + 1e-6 * x[1]**2\n",
    "    return 12 * x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11362be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR1 needed 0.00579155683517456 seconds\n",
      "Newton needed 0.024589478969573975 seconds\n"
     ]
    }
   ],
   "source": [
    "robust_race(noisy_polynomial_f, [1.2,1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5e11ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR1 needed 0.006417906284332276 seconds\n",
      "Newton needed 0.03006303310394287 seconds\n"
     ]
    }
   ],
   "source": [
    "robust_race(noisy_polynomial_f, [12,2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d187867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_polynomial_f(x):\n",
    "    if not np.random.randint(0, 5): return x[0]**2 + 1e-6 * x[1]**2\n",
    "    return 12 * x[0]**2 + x[1]**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
